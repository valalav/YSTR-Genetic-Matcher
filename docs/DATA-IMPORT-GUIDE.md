# Data Import Guide
## Ğ ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñƒ CSV Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² PostgreSQL

---

## ğŸ“Š Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

### CSV Files (Ğ² `scripts/downloads/`)

| Ğ¤Ğ°Ğ¹Ğ» | Ğ Ğ°Ğ·Ğ¼ĞµÑ€ | Ğ“Ğ°Ğ¿Ğ»Ğ¾Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° | ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾Ğµ ĞºĞ¾Ğ»-Ğ²Ğ¾ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹ |
|------|--------|-------------|---------------------------|
| `I.csv` | 16 MB | I | ~40,000 |
| `r1a.csv` | 6.9 MB | R1a | ~18,000 |
| `E.csv` | 5.9 MB | E | ~15,000 |
| `Others.csv` | 5.5 MB | Others | ~14,000 |
| `J2.csv` | 5.0 MB | J2 | ~13,000 |
| `J1.csv` | 4.8 MB | J1 | ~12,000 |
| `G.csv` | 3.2 MB | G | ~8,000 |
| `aadna.csv` | 0 KB | AADNA | 0 (Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹) |
| `Genopoisk.csv` | 16 KB | Mixed | ~40 |
| **Ğ˜Ğ¢ĞĞ“Ğ** | **~47 MB** | **Mixed** | **~120,000** |

### Google Sheets Sources

Ğ’ÑĞµ CSV Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· API (Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ñ‹ Ğ² `str-matcher/src/config/repositories.config.ts`):

- **AADNA.ru**: https://docs.google.com/spreadsheets/.../output=csv
- **R1a**: https://docs.google.com/spreadsheets/.../output=csv
- **E, G, I, J1, J2, Others**: Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ğ¾

### R1b Database (Chunked JSON)

R1b - ÑĞ°Ğ¼Ğ°Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ°Ñ Ğ±Ğ°Ğ·Ğ° (~50,000+ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹), Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑÑ Ğ² chunked JSON Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ:
- `/public/chunk_0.json` through `/public/chunk_15.json`
- 16 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²
- Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸

---

## ğŸ—ï¸ Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°

### Ğ­Ñ‚Ğ°Ğ¿ 1: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ‘Ğ”

```sql
-- 1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
CREATE TABLE haplogroup_databases (
    id SERIAL PRIMARY KEY,
    haplogroup VARCHAR(50) NOT NULL UNIQUE,
    total_profiles INTEGER DEFAULT 0,
    loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status VARCHAR(20) DEFAULT 'active',
    source_file VARCHAR(255),
    avg_markers DECIMAL(5,2),
    file_size_mb DECIMAL(10,2),
    description TEXT
);
```

### Ğ­Ñ‚Ğ°Ğ¿ 2: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ñ… Ğ±Ğ°Ğ· (Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ)

ĞĞ°Ñ‡Ğ½Ñ‘Ğ¼ Ñ ÑĞ°Ğ¼Ñ‹Ñ… Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ñ… Ğ±Ğ°Ğ· Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°:

1. **Genopoisk.csv** (16 KB, ~40 Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹)
2. **G.csv** (3.2 MB, ~8,000 Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹)
3. **J1.csv** (4.8 MB, ~12,000 Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹)

**Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°:**
```javascript
// backend/scripts/import-csv-to-postgres.js
const fs = require('fs');
const Papa = require('papaparse');
const { pool } = require('../config/database');

async function importCSV(filePath, haplogroup) {
  console.log(`Importing ${filePath}...`);

  const csvContent = fs.readFileSync(filePath, 'utf-8');
  const parseResult = Papa.parse(csvContent, {
    header: true,
    skipEmptyLines: true
  });

  // Transform to profile objects
  const profiles = parseResult.data.map(row => ({
    kitNumber: row.kitNumber || row.kit_number || row.KitNumber,
    name: row.name || row.Name || '',
    country: row.country || row.Country || '',
    haplogroup: row.haplogroup || row.Haplogroup || haplogroup,
    markers: extractMarkers(row)
  })).filter(p => p.kitNumber && Object.keys(p.markers).length > 0);

  console.log(`Found ${profiles.length} valid profiles`);

  // Bulk insert in batches of 5000
  const batchSize = 5000;
  let inserted = 0;

  for (let i = 0; i < profiles.length; i += batchSize) {
    const batch = profiles.slice(i, i + batchSize);
    const result = await pool.query(
      'SELECT bulk_insert_profiles($1)',
      [JSON.stringify(batch)]
    );
    inserted += result.rows[0].bulk_insert_profiles;
    console.log(`Progress: ${inserted}/${profiles.length}`);
  }

  console.log(`âœ… Imported ${inserted} profiles`);
  return inserted;
}

function extractMarkers(row) {
  const markers = {};
  const excludeKeys = ['kitnumber', 'kit_number', 'name', 'country', 'haplogroup'];

  Object.keys(row).forEach(key => {
    if (!excludeKeys.includes(key.toLowerCase()) && row[key] && row[key] !== '') {
      markers[key] = row[key];
    }
  });

  return markers;
}

// Usage
importCSV('./scripts/downloads/Genopoisk.csv', 'Mixed').then(() => process.exit(0));
```

### Ğ­Ñ‚Ğ°Ğ¿ 3: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ… Ğ±Ğ°Ğ·

ĞŸĞ¾ÑĞ»Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ¼Ğ°Ğ»Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:

4. **J2.csv** (5.0 MB, ~13,000 Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹)
5. **Others.csv** (5.5 MB, ~14,000 Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹)
6. **E.csv** (5.9 MB, ~15,000 Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹)

### Ğ­Ñ‚Ğ°Ğ¿ 4: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ±Ğ°Ğ·

Ğ¡Ğ°Ğ¼Ñ‹Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ğ±Ğ°Ğ·Ñ‹ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:

7. **r1a.csv** (6.9 MB, ~18,000 Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹)
8. **I.csv** (16 MB, ~40,000 Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹)

**ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ²:**
- ĞÑ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ñ‹ (`ALTER TABLE ystr_profiles DISABLE TRIGGER ALL`)
- Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ `work_mem` Ğ¸ `maintenance_work_mem`
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ `COPY` Ğ²Ğ¼ĞµÑÑ‚Ğ¾ `INSERT` (Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ² 10 Ñ€Ğ°Ğ·)
- Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¸Ğ½Ğ´ĞµĞºÑÑ‹ ĞŸĞĞ¡Ğ›Ğ• Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°

### Ğ­Ñ‚Ğ°Ğ¿ 5: R1b Chunked JSON

R1b Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ°:

```javascript
// backend/scripts/import-r1b-chunks.js
async function importR1bChunks() {
  const totalChunks = 16;
  let totalProfiles = 0;

  for (let i = 0; i < totalChunks; i++) {
    const chunkPath = `./public/chunk_${i}.json`;
    const chunkData = JSON.parse(fs.readFileSync(chunkPath, 'utf-8'));

    // Convert JSON to profile format
    const profiles = chunkData.map(item => ({
      kitNumber: item.id || item.kitNumber,
      name: item.name || '',
      country: item.country || '',
      haplogroup: item.haplogroup || 'R1b',
      markers: item.markers || {}
    }));

    const inserted = await bulkInsert(profiles);
    totalProfiles += inserted;
    console.log(`Chunk ${i + 1}/${totalChunks}: ${inserted} profiles (total: ${totalProfiles})`);
  }

  return totalProfiles;
}
```

---

## ğŸ“‹ ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ğ½ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°

### Ğ”ĞµĞ½ÑŒ 1: ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

```bash
# 1. Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ÑŒÑÑ Ñ‡Ñ‚Ğ¾ PostgreSQL Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½
psql -U postgres -c "SELECT version();"

# 2. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ±Ğ°Ğ·Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚)
psql -U postgres -c "CREATE DATABASE ystr_matcher;"

# 3. ĞŸÑ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ ÑÑ…ĞµĞ¼Ñƒ
psql -U postgres -d ystr_matcher -f database/schema.sql

# 4. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
psql -U postgres -d ystr_matcher -f database/haplogroup-databases-table.sql

# 5. Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ (Genopoisk - 40 Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹)
node backend/scripts/import-csv-to-postgres.js --file=scripts/downloads/Genopoisk.csv --haplogroup=Mixed

# 6. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
psql -U postgres -d ystr_matcher -c "SELECT COUNT(*) FROM ystr_profiles;"
```

### Ğ”ĞµĞ½ÑŒ 2: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¼Ğ°Ğ»Ñ‹Ñ… Ğ¸ ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ… Ğ±Ğ°Ğ·

```bash
# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ G (8k profiles)
node backend/scripts/import-csv-to-postgres.js --file=scripts/downloads/G.csv --haplogroup=G

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ J1 (12k profiles)
node backend/scripts/import-csv-to-postgres.js --file=scripts/downloads/J1.csv --haplogroup=J1

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ J2 (13k profiles)
node backend/scripts/import-csv-to-postgres.js --file=scripts/downloads/J2.csv --haplogroup=J2

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ E (15k profiles)
node backend/scripts/import-csv-to-postgres.js --file=scripts/downloads/E.csv --haplogroup=E

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Others (14k profiles)
node backend/scripts/import-csv-to-postgres.js --file=scripts/downloads/Others.csv --haplogroup=Others

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ
psql -U postgres -d ystr_matcher -c "SELECT haplogroup, COUNT(*) as count FROM ystr_profiles GROUP BY haplogroup;"
```

### Ğ”ĞµĞ½ÑŒ 3: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ±Ğ°Ğ·

```bash
# ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ²
psql -U postgres -d ystr_matcher <<EOF
ALTER TABLE ystr_profiles DISABLE TRIGGER ALL;
SET work_mem = '256MB';
SET maintenance_work_mem = '1GB';
EOF

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ r1a (18k profiles)
node backend/scripts/import-csv-to-postgres.js --file=scripts/downloads/r1a.csv --haplogroup=R1a

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ I (40k profiles)
node backend/scripts/import-csv-to-postgres.js --file=scripts/downloads/I.csv --haplogroup=I

# Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾
psql -U postgres -d ystr_matcher -c "ALTER TABLE ystr_profiles ENABLE TRIGGER ALL;"

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¸Ğ½Ğ´ĞµĞºÑÑ‹
psql -U postgres -d ystr_matcher -c "REINDEX TABLE ystr_profiles;"
psql -U postgres -d ystr_matcher -c "REFRESH MATERIALIZED VIEW marker_statistics;"
```

### Ğ”ĞµĞ½ÑŒ 4: R1b Ğ¸ Ñ„Ğ¸Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

```bash
# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ R1b chunks (50k+ profiles)
node backend/scripts/import-r1b-chunks.js

# Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°
psql -U postgres -d ystr_matcher <<EOF
SELECT
    haplogroup,
    COUNT(*) as profiles,
    AVG((SELECT COUNT(*) FROM jsonb_object_keys(markers))) as avg_markers
FROM ystr_profiles
GROUP BY haplogroup
ORDER BY profiles DESC;

SELECT COUNT(*) as total_profiles FROM ystr_profiles;
EOF

# ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ‘Ğ”
psql -U postgres -d ystr_matcher -c "VACUUM ANALYZE ystr_profiles;"
```

---

## âš¡ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸

### PostgreSQL Settings

```sql
-- Ğ”Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
ALTER SYSTEM SET shared_buffers = '2GB';
ALTER SYSTEM SET effective_cache_size = '6GB';
ALTER SYSTEM SET work_mem = '256MB';
ALTER SYSTEM SET maintenance_work_mem = '1GB';
ALTER SYSTEM SET max_worker_processes = 8;
ALTER SYSTEM SET max_parallel_workers = 8;

-- ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ PostgreSQL Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
-- sudo systemctl restart postgresql
```

### Batch Insert Optimization

```javascript
// Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ bulk_insert_profiles() Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… INSERT
const batchSize = 5000; // Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±Ğ°Ñ‚Ñ‡Ğ°

// BAD (Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾):
for (const profile of profiles) {
  await pool.query('INSERT INTO ystr_profiles ...', [profile]);
}

// GOOD (Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾):
for (let i = 0; i < profiles.length; i += batchSize) {
  const batch = profiles.slice(i, i + batchSize);
  await pool.query('SELECT bulk_insert_profiles($1)', [JSON.stringify(batch)]);
}
```

### Progress Tracking

```javascript
const ProgressBar = require('progress');

const bar = new ProgressBar('Importing [:bar] :percent :etas', {
  total: profiles.length,
  width: 40
});

for (let i = 0; i < profiles.length; i += batchSize) {
  // ... import batch ...
  bar.tick(Math.min(batchSize, profiles.length - i));
}
```

---

## ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ

### ĞŸĞ¾ÑĞ»Ğµ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ±Ğ°Ğ·Ñ‹:

```sql
-- 1. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹
SELECT COUNT(*) FROM ystr_profiles WHERE haplogroup = 'R1a';

-- 2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑÑ€ĞµĞ´Ğ½ĞµĞµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¼Ğ°Ñ€ĞºĞµÑ€Ğ¾Ğ²
SELECT
    haplogroup,
    AVG((SELECT COUNT(*) FROM jsonb_object_keys(markers))) as avg_markers
FROM ystr_profiles
WHERE haplogroup = 'R1a'
GROUP BY haplogroup;

-- 3. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹ kit_number
SELECT kit_number, COUNT(*)
FROM ystr_profiles
GROUP BY kit_number
HAVING COUNT(*) > 1;

-- 4. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸ Ğ±ĞµĞ· Ğ¼Ğ°Ñ€ĞºĞµÑ€Ğ¾Ğ²
SELECT COUNT(*)
FROM ystr_profiles
WHERE jsonb_object_keys(markers) IS NULL;

-- 5. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ğ¿-10 Ğ¼Ğ°Ñ€ĞºĞµÑ€Ğ¾Ğ²
SELECT
    key as marker_name,
    COUNT(*) as profiles_with_marker
FROM ystr_profiles, jsonb_object_keys(markers)
WHERE haplogroup = 'R1a'
GROUP BY key
ORDER BY profiles_with_marker DESC
LIMIT 10;
```

---

## ğŸš¨ Troubleshooting

### ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: "Duplicate key value violates unique constraint"

**ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°:** Ğ”ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹ kit_number Ğ² CSV

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:**
```javascript
// Ğ’ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ import, Ğ¿ĞµÑ€ĞµĞ´ bulk_insert:
const uniqueProfiles = profiles.reduce((acc, profile) => {
  acc[profile.kitNumber] = profile; // Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ wins
  return acc;
}, {});

const deduplicatedProfiles = Object.values(uniqueProfiles);
console.log(`Removed ${profiles.length - deduplicatedProfiles.length} duplicates`);
```

### ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: "Out of memory"

**ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°:** Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ batch size

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:**
```javascript
// Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ñ‚ÑŒ batch size
const batchSize = 1000; // Ğ²Ğ¼ĞµÑÑ‚Ğ¾ 5000
```

### ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: "Connection timeout"

**ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°:** Ğ”Ğ¾Ğ»Ğ³Ğ¸Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:**
```javascript
// Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ timeout Ğ² database.js
const pool = new Pool({
  // ...
  connectionTimeoutMillis: 60000, // 60 ÑĞµĞºÑƒĞ½Ğ´
  statement_timeout: 300000, // 5 Ğ¼Ğ¸Ğ½ÑƒÑ‚
  query_timeout: 300000
});
```

---

## ğŸ“Š ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚

ĞŸĞ¾ÑĞ»Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Haplogroup â•‘ Profiles     â•‘ Avg Markers   â•‘ File Size    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ R1b        â•‘ ~50,000      â•‘ 37.5          â•‘ Chunked JSON â•‘
â•‘ I          â•‘ ~40,000      â•‘ 36.2          â•‘ 16 MB        â•‘
â•‘ R1a        â•‘ ~18,000      â•‘ 38.1          â•‘ 6.9 MB       â•‘
â•‘ E          â•‘ ~15,000      â•‘ 35.8          â•‘ 5.9 MB       â•‘
â•‘ Others     â•‘ ~14,000      â•‘ 34.5          â•‘ 5.5 MB       â•‘
â•‘ J2         â•‘ ~13,000      â•‘ 36.9          â•‘ 5.0 MB       â•‘
â•‘ J1         â•‘ ~12,000      â•‘ 37.3          â•‘ 4.8 MB       â•‘
â•‘ G          â•‘ ~8,000       â•‘ 35.1          â•‘ 3.2 MB       â•‘
â•‘ Mixed      â•‘ ~40          â•‘ 25.0          â•‘ 16 KB        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ **TOTAL**  â•‘ **~170,000** â•‘ **36.8**      â•‘ **~47 MB**   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ¯ Next Steps

1. âœ… Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ²ÑĞµÑ… Ğ±Ğ°Ğ· (170k profiles)
2. â­ï¸ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ UI Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ³Ğ°Ğ¿Ğ»Ğ¾Ğ³Ñ€ÑƒĞ¿Ğ¿
3. â­ï¸ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ¸ÑĞº (Ğ¿Ğ°Ñ€Ñ‚Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ)
4. â­ï¸ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ³Ğ°Ğ¿Ğ»Ğ¾Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼
5. â­ï¸ Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸

---

**Ğ”Ğ°Ñ‚Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ:** 2025-10-04
**ĞĞ²Ñ‚Ğ¾Ñ€:** Claude Code
**Ğ’ĞµÑ€ÑĞ¸Ñ:** 1.0
