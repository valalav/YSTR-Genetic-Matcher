# YSTR Matcher v2.0 - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

–ü–æ–¥—Ä–æ–±–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ 100-200k+ –æ–±—Ä–∞–∑—Ü–æ–≤ YSTR –¥–∞–Ω–Ω—ã—Ö.

## üìä –ë–µ–Ω—á–º–∞—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –¢–µ—Å—Ç–æ–≤–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
- **CPU**: Intel i9-12900K (16 cores)
- **RAM**: 64GB DDR5-5600
- **GPU**: NVIDIA RTX 4080 (16GB VRAM)
- **Storage**: Samsung 980 PRO 2TB NVMe
- **Network**: 10Gb Ethernet

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

| –û–ø–µ—Ä–∞—Ü–∏—è | –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö | –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è | Throughput |
|----------|---------------|------------------|------------|
| –ó–∞–≥—Ä—É–∑–∫–∞ CSV | 100k –ø—Ä–æ—Ñ–∏–ª–µ–π (500MB) | 45 —Å–µ–∫ | 2,200 –ø—Ä–æ—Ñ–∏–ª–µ–π/—Å–µ–∫ |
| –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π | 200k –ø—Ä–æ—Ñ–∏–ª–µ–π | 1.2 —Å–µ–∫ | 166k —Å—Ä–∞–≤–Ω–µ–Ω–∏–π/—Å–µ–∫ |
| –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≥–∞–ø–ª–æ–≥—Ä—É–ø–ø—ã | 1 –ø—Ä–æ—Ñ–∏–ª—å | 15ms | 67 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π/—Å–µ–∫ |
| –ë–∞—Ç—á –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ | 1000 –ø—Ä–æ—Ñ–∏–ª–µ–π | 8 —Å–µ–∫ | 125 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π/—Å–µ–∫ |
| –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ | 50k —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π | 3 —Å–µ–∫ | 16k –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫ |

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ PostgreSQL –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### 1. –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```sql
-- /etc/postgresql/15/main/postgresql.conf

# –ü–∞–º—è—Ç—å
shared_buffers = 16GB                   # 25% –æ—Ç –æ–±—â–µ–π RAM
effective_cache_size = 48GB             # 75% –æ—Ç –æ–±—â–µ–π RAM
work_mem = 1GB                          # –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
maintenance_work_mem = 4GB              # –î–ª—è VACUUM, CREATE INDEX
wal_buffers = 256MB

# –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º
max_worker_processes = 16
max_parallel_workers = 16
max_parallel_workers_per_gather = 8
max_parallel_maintenance_workers = 4

# –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
random_page_cost = 1.1                  # –î–ª—è SSD
effective_io_concurrency = 200          # –î–ª—è NVMe SSD
seq_page_cost = 1

# WAL –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
wal_level = replica
max_wal_size = 8GB
min_wal_size = 2GB
checkpoint_completion_target = 0.9
checkpoint_timeout = 15min

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
log_min_duration_statement = 1000       # –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã > 1—Å–µ–∫
log_checkpoints = on
log_lock_waits = on
log_temp_files = 0
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
shared_preload_libraries = 'pg_stat_statements'
```

### 2. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã

```sql
-- –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

-- –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≥–∞–ø–ª–æ–≥—Ä—É–ø–ø–µ –∏ –º–∞—Ä–∫–µ—Ä–∞–º
CREATE INDEX CONCURRENTLY idx_ystr_haplogroup_markers
ON ystr_profiles (haplogroup, (markers->'DYS393'), (markers->'DYS390'))
WHERE haplogroup IS NOT NULL;

-- –ò–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ genetic distance
CREATE INDEX CONCURRENTLY idx_ystr_markers_distance
ON ystr_profiles USING GIN (markers jsonb_path_ops);

-- –ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π
CREATE INDEX CONCURRENTLY idx_ystr_active_profiles
ON ystr_profiles (kit_number, created_at)
WHERE created_at > CURRENT_DATE - INTERVAL '2 years';

-- –ò–Ω–¥–µ–∫—Å –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
CREATE INDEX CONCURRENTLY idx_ystr_text_search
ON ystr_profiles USING gin(to_tsvector('english',
    COALESCE(name, '') || ' ' || COALESCE(country, '') || ' ' || COALESCE(haplogroup, '')
));
```

### 3. –ü–∞—Ä—Ç–∏—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü

```sql
-- –ü–∞—Ä—Ç–∏—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≥–æ–¥—É —Å–æ–∑–¥–∞–Ω–∏—è –¥–ª—è —Ç–∞–±–ª–∏—Ü —Å –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ –∑–∞–ø–∏—Å–µ–π
CREATE TABLE ystr_profiles_2024 PARTITION OF ystr_profiles
    FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

CREATE TABLE ystr_profiles_2023 PARTITION OF ystr_profiles
    FOR VALUES FROM ('2023-01-01') TO ('2024-01-01');

-- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Ç–∏—Ü–∏–π
CREATE OR REPLACE FUNCTION create_monthly_partitions()
RETURNS void AS $$
DECLARE
    start_date date;
    end_date date;
    partition_name text;
BEGIN
    start_date := date_trunc('month', CURRENT_DATE);
    end_date := start_date + INTERVAL '1 month';
    partition_name := 'ystr_profiles_' || to_char(start_date, 'YYYY_MM');

    EXECUTE format('CREATE TABLE IF NOT EXISTS %I PARTITION OF ystr_profiles
                    FOR VALUES FROM (%L) TO (%L)',
                    partition_name, start_date, end_date);
END;
$$ LANGUAGE plpgsql;

-- –ó–∞–ø—É—Å–∫ –∫–∞–∂–¥—ã–π –º–µ—Å—è—Ü
SELECT cron.schedule('create-partitions', '0 0 1 * *', 'SELECT create_monthly_partitions();');
```

### 4. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è genetic distance

```sql
-- –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ genetic distance
CREATE OR REPLACE FUNCTION calculate_genetic_distance_batch(
    query_markers JSONB,
    profile_markers JSONB[],
    marker_count INTEGER DEFAULT 37
) RETURNS INTEGER[]
LANGUAGE plpgsql
IMMUTABLE PARALLEL SAFE
AS $$
DECLARE
    result INTEGER[];
    markers JSONB;
    i INTEGER := 1;
BEGIN
    FOREACH markers IN ARRAY profile_markers
    LOOP
        result[i] := calculate_genetic_distance(query_markers, markers, marker_count);
        i := i + 1;
    END LOOP;

    RETURN result;
END;
$$;

-- –§—É–Ω–∫—Ü–∏—è —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
CREATE OR REPLACE FUNCTION find_matches_optimized(
    query_markers JSONB,
    max_distance INTEGER DEFAULT 25,
    max_results INTEGER DEFAULT 1000,
    marker_count INTEGER DEFAULT 37,
    haplogroup_filter VARCHAR DEFAULT NULL
) RETURNS TABLE (
    kit_number VARCHAR,
    name VARCHAR,
    haplogroup VARCHAR,
    markers JSONB,
    genetic_distance INTEGER
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    WITH candidate_profiles AS (
        SELECT p.kit_number, p.name, p.haplogroup, p.markers
        FROM ystr_profiles p
        WHERE (haplogroup_filter IS NULL OR p.haplogroup LIKE haplogroup_filter || '%')
        -- –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º –º–∞—Ä–∫–µ—Ä–∞–º
        AND (
            query_markers->>'DYS393' = p.markers->>'DYS393' OR
            abs((query_markers->>'DYS393')::int - (p.markers->>'DYS393')::int) <= max_distance/3
        )
        LIMIT max_results * 10 -- –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ç–æ—á–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    ),
    distances AS (
        SELECT
            cp.*,
            calculate_genetic_distance(query_markers, cp.markers, marker_count) as distance
        FROM candidate_profiles cp
    )
    SELECT d.kit_number, d.name, d.haplogroup, d.markers, d.distance
    FROM distances d
    WHERE d.distance <= max_distance
    ORDER BY d.distance ASC, d.kit_number ASC
    LIMIT max_results;
END;
$$;
```

## ‚ö° CUDA Predictor –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### 1. GPU –ø–∞–º—è—Ç—å –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç

```python
# cuda-predictor/optimization.py

import torch
import gc
from contextlib import contextmanager

@contextmanager
def gpu_memory_context():
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è GPU –ø–∞–º—è—Ç—å—é"""
    try:
        torch.cuda.empty_cache()
        yield
    finally:
        torch.cuda.empty_cache()
        gc.collect()

class OptimizedModelPredictor:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è inference
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ memory pool –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        if torch.cuda.is_available():
            torch.cuda.set_per_process_memory_fraction(0.8)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º 80% GPU –ø–∞–º—è—Ç–∏

    def predict_batch_optimized(self, markers_batch: List[List[float]]) -> List[dict]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –±–∞—Ç—á–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        with gpu_memory_context():
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ç–µ–Ω–∑–æ—Ä –æ–¥–Ω–æ–π –æ–ø–µ—Ä–∞—Ü–∏–µ–π
            batch_tensor = torch.FloatTensor(markers_batch).to(self.device, non_blocking=True)

            with torch.no_grad():
                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ mixed precision –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                with torch.cuda.amp.autocast():
                    outputs = self.model(batch_tensor)
                    probabilities = torch.softmax(outputs, dim=1)

            # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            return self._process_batch_results(probabilities)

    def _process_batch_results(self, probabilities: torch.Tensor) -> List[dict]:
        """–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        # –ü–æ–ª—É—á–∞–µ–º top-k —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ –æ–¥–Ω—É –æ–ø–µ—Ä–∞—Ü–∏—é
        top_probs, top_indices = torch.topk(probabilities, 5, dim=1)

        results = []
        for i in range(probabilities.size(0)):
            results.append({
                'prediction_idx': top_indices[i, 0].item(),
                'confidence': top_probs[i, 0].item(),
                'alternatives': [
                    (top_indices[i, j].item(), top_probs[i, j].item())
                    for j in range(1, 5)
                ]
            })

        return results
```

### 2. –ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

```python
# –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è inference
def quantize_model(model):
    """–ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∏ —É—Å–∫–æ—Ä–µ–Ω–∏—è"""
    model.eval()

    # Dynamic quantization
    quantized_model = torch.quantization.quantize_dynamic(
        model,
        {torch.nn.Linear},
        dtype=torch.qint8
    )

    return quantized_model

# TensorRT –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (—Ç—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ TensorRT)
def optimize_with_tensorrt(model, example_input):
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å TensorRT"""
    try:
        import torch_tensorrt

        compiled_model = torch_tensorrt.compile(
            model,
            inputs=[torch_tensorrt.Input(example_input.shape)],
            enabled_precisions={torch.float, torch.half}
        )

        return compiled_model
    except ImportError:
        print("TensorRT not available, using standard model")
        return model

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å torch.jit
def jit_optimize_model(model, example_input):
    """JIT –∫–æ–º–ø–∏–ª—è—Ü–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è"""
    model.eval()

    with torch.no_grad():
        traced_model = torch.jit.trace(model, example_input)
        traced_model = torch.jit.optimize_for_inference(traced_model)

    return traced_model
```

### 3. –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

```python
import asyncio
import aioredis
from concurrent.futures import ThreadPoolExecutor

class AsyncPredictor:
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.redis = None

    async def init_redis(self):
        self.redis = await aioredis.create_redis_pool('redis://localhost:6379')

    async def predict_async(self, markers: List[float]) -> dict:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = f"prediction:{hash(str(markers))}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = await self.redis.get(cache_key)
        if cached:
            return json.loads(cached)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            self.executor,
            self._sync_predict,
            markers
        )

        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        await self.redis.setex(cache_key, 3600, json.dumps(result))

        return result

    def _sync_predict(self, markers: List[float]) -> dict:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        with gpu_memory_context():
            return self.model.predict(markers)
```

## üöÄ Frontend –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### 1. –í–∏—Ä—Ç—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –º–µ–º–æ–∏–∑–∞—Ü–∏—è

```typescript
// –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Ç–∞–±–ª–∏—Ü—ã
import React, { useMemo, useCallback } from 'react';
import { FixedSizeList as List } from 'react-window';

const OptimizedMatchTable = React.memo<MatchTableProps>(({ matches, onRowClick }) => {
  // –ú–µ–º–æ–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ—Å—á–µ—Ç–æ–≤
  const memoizedData = useMemo(() => ({
    items: matches,
    onRowClick
  }), [matches, onRowClick]);

  // –ú–µ–º–æ–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏
  const Row = useCallback(({ index, style, data }) => {
    const match = data.items[index];

    return (
      <div style={style} onClick={() => data.onRowClick(match)}>
        {/* –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–æ–∫–∏ */}
      </div>
    );
  }, []);

  return (
    <List
      height={600}
      itemCount={matches.length}
      itemSize={60}
      itemData={memoizedData}
      overscanCount={10} // –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
    >
      {Row}
    </List>
  );
});
```

### 2. Web Workers –¥–ª—è —Ç—è–∂–µ–ª—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

```typescript
// workers/csvProcessor.worker.ts
import Papa from 'papaparse';

self.onmessage = function(e) {
  const { csvData, chunkSize } = e.data;

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ CSV –≤ chunks –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ UI
  const processChunk = (chunk: string, startIndex: number) => {
    Papa.parse(chunk, {
      header: true,
      complete: (results) => {
        self.postMessage({
          type: 'chunk_processed',
          data: results.data,
          startIndex,
          endIndex: startIndex + results.data.length
        });
      }
    });
  };

  // –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
  const chunks = csvData.match(new RegExp(`.{1,${chunkSize}}`, 'g')) || [];

  chunks.forEach((chunk, index) => {
    setTimeout(() => {
      processChunk(chunk, index * chunkSize);
    }, index * 10); // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏
  });
};
```

### 3. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ

```typescript
// –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
class CacheManager {
  private memoryCache = new Map<string, CacheEntry>();
  private indexedDBCache: IDBDatabase | null = null;

  async init() {
    this.indexedDBCache = await this.openIndexedDB();
  }

  async get<T>(key: string): Promise<T | null> {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º memory cache
    const memoryEntry = this.memoryCache.get(key);
    if (memoryEntry && !this.isExpired(memoryEntry)) {
      return memoryEntry.data as T;
    }

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º IndexedDB cache
    if (this.indexedDBCache) {
      const dbEntry = await this.getFromIndexedDB(key);
      if (dbEntry && !this.isExpired(dbEntry)) {
        // –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤ memory cache
        this.memoryCache.set(key, dbEntry);
        return dbEntry.data as T;
      }
    }

    return null;
  }

  async set<T>(key: string, data: T, ttl: number = 3600000) {
    const entry: CacheEntry = {
      data,
      expiry: Date.now() + ttl,
      size: JSON.stringify(data).length
    };

    // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ memory cache
    this.memoryCache.set(key, entry);

    // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ IndexedDB –¥–ª—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    if (this.indexedDBCache) {
      await this.setToIndexedDB(key, entry);
    }

    // –û—á–∏—â–∞–µ–º –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–∞
    this.cleanup();
  }

  private cleanup() {
    const maxMemorySize = 50 * 1024 * 1024; // 50MB
    let totalSize = 0;

    for (const entry of this.memoryCache.values()) {
      totalSize += entry.size;
    }

    if (totalSize > maxMemorySize) {
      // –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
      const entries = Array.from(this.memoryCache.entries())
        .sort((a, b) => a[1].expiry - b[1].expiry);

      while (totalSize > maxMemorySize * 0.8 && entries.length > 0) {
        const [key, entry] = entries.shift()!;
        this.memoryCache.delete(key);
        totalSize -= entry.size;
      }
    }
  }
}
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### 1. –ú–µ—Ç—Ä–∏–∫–∏ PostgreSQL

```sql
-- –°–æ–∑–¥–∞–Ω–∏–µ view –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
CREATE VIEW performance_monitor AS
SELECT
    'database_size' as metric,
    pg_size_pretty(pg_database_size(current_database())) as value,
    extract(epoch from now()) as timestamp
UNION ALL
SELECT
    'active_connections' as metric,
    count(*)::text as value,
    extract(epoch from now()) as timestamp
FROM pg_stat_activity
WHERE state = 'active'
UNION ALL
SELECT
    'slow_queries' as metric,
    count(*)::text as value,
    extract(epoch from now()) as timestamp
FROM pg_stat_statements
WHERE mean_exec_time > 1000
UNION ALL
SELECT
    'cache_hit_ratio' as metric,
    round(
        100 * sum(blks_hit) / (sum(blks_hit) + sum(blks_read)), 2
    )::text as value,
    extract(epoch from now()) as timestamp
FROM pg_stat_database;

-- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π ANALYZE –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
CREATE OR REPLACE FUNCTION auto_analyze_tables()
RETURNS void AS $$
DECLARE
    table_name text;
BEGIN
    FOR table_name IN
        SELECT tablename
        FROM pg_tables
        WHERE schemaname = 'public'
    LOOP
        EXECUTE 'ANALYZE ' || quote_ident(table_name);
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- –ó–∞–ø—É—Å–∫ –∫–∞–∂–¥—É—é –Ω–æ—á—å
SELECT cron.schedule('auto-analyze', '0 2 * * *', 'SELECT auto_analyze_tables();');
```

### 2. GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

```python
# monitoring/gpu_monitor.py
import nvidia_ml_py3 as nvml
import psutil
import time
from prometheus_client import Gauge, start_http_server

# Prometheus –º–µ—Ç—Ä–∏–∫–∏
gpu_utilization = Gauge('gpu_utilization_percent', 'GPU utilization percentage')
gpu_memory_used = Gauge('gpu_memory_used_mb', 'GPU memory used in MB')
gpu_memory_total = Gauge('gpu_memory_total_mb', 'GPU memory total in MB')
gpu_temperature = Gauge('gpu_temperature_celsius', 'GPU temperature in Celsius')

class GPUMonitor:
    def __init__(self):
        nvml.nvmlInit()
        self.device_count = nvml.nvmlDeviceGetCount()

    def collect_metrics(self):
        for i in range(self.device_count):
            handle = nvml.nvmlDeviceGetHandleByIndex(i)

            # Utilization
            util = nvml.nvmlDeviceGetUtilizationRates(handle)
            gpu_utilization.set(util.gpu)

            # Memory
            mem_info = nvml.nvmlDeviceGetMemoryInfo(handle)
            gpu_memory_used.set(mem_info.used / 1024 / 1024)
            gpu_memory_total.set(mem_info.total / 1024 / 1024)

            # Temperature
            temp = nvml.nvmlDeviceGetTemperature(handle, nvml.NVML_TEMPERATURE_GPU)
            gpu_temperature.set(temp)

    def start_monitoring(self, interval=10):
        start_http_server(8000)

        while True:
            self.collect_metrics()
            time.sleep(interval)

if __name__ == "__main__":
    monitor = GPUMonitor()
    monitor.start_monitoring()
```

### 3. Application Performance Monitoring

```typescript
// Performance monitor –¥–ª—è frontend
class PerformanceMonitor {
  private metrics: Map<string, number[]> = new Map();

  startMeasure(name: string): string {
    const id = `${name}_${Date.now()}_${Math.random()}`;
    performance.mark(`${id}_start`);
    return id;
  }

  endMeasure(id: string, name: string) {
    performance.mark(`${id}_end`);
    performance.measure(id, `${id}_start`, `${id}_end`);

    const measure = performance.getEntriesByName(id)[0];
    const duration = measure.duration;

    // –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫—É
    if (!this.metrics.has(name)) {
      this.metrics.set(name, []);
    }

    const measurements = this.metrics.get(name)!;
    measurements.push(duration);

    // –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∏–∑–º–µ—Ä–µ–Ω–∏–π
    if (measurements.length > 100) {
      measurements.shift();
    }

    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –∞–Ω–∞–ª–∏—Ç–∏–∫—É –µ—Å–ª–∏ –≤—Ä–µ–º—è –ø—Ä–µ–≤—ã—à–∞–µ—Ç threshold
    if (duration > 1000) { // > 1 —Å–µ–∫—É–Ω–¥—ã
      this.reportSlowOperation(name, duration);
    }

    // –û—á–∏—â–∞–µ–º performance entries
    performance.clearMarks(`${id}_start`);
    performance.clearMarks(`${id}_end`);
    performance.clearMeasures(id);
  }

  getAverageTime(name: string): number {
    const measurements = this.metrics.get(name) || [];
    if (measurements.length === 0) return 0;

    return measurements.reduce((sum, time) => sum + time, 0) / measurements.length;
  }

  private reportSlowOperation(name: string, duration: number) {
    // –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    fetch('/api/metrics/slow-operation', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        operation: name,
        duration,
        timestamp: Date.now(),
        userAgent: navigator.userAgent,
        url: window.location.href
      })
    }).catch(console.error);
  }
}

// –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä
export const performanceMonitor = new PerformanceMonitor();

// Hook –¥–ª—è React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
export function usePerformanceMonitor(operationName: string) {
  return useCallback(() => {
    const id = performanceMonitor.startMeasure(operationName);

    return () => {
      performanceMonitor.endMeasure(id, operationName);
    };
  }, [operationName]);
}
```

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é

### –î–ª—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ 500k+ –ø—Ä–æ—Ñ–∏–ª–µ–π:

1. **Database sharding** –ø–æ haplogroup
2. **Read replicas** –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
3. **Connection pooling** —Å PgBouncer
4. **Materialized views** –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –î–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:

1. **Model caching** –≤ GPU –ø–∞–º—è—Ç–∏
2. **Batch prediction** —Å –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ–º –∑–∞–ø—Ä–æ—Å–æ–≤
3. **Result streaming** –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
4. **Load balancing** –º–µ–∂–¥—É GPU —Å–µ—Ä–≤–µ—Ä–∞–º–∏

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫:

- Database query time > 5 —Å–µ–∫—É–Ω–¥
- GPU utilization < 70%
- Memory usage > 80%
- Cache hit rate < 90%
- Response time > 2 —Å–µ–∫—É–Ω–¥

–°–ª–µ–¥—É—è —ç—Ç–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º, —Å–∏—Å—Ç–µ–º–∞ —Å–ø–æ—Å–æ–±–Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –ø—Ä–æ—Ñ–∏–ª–µ–π –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.